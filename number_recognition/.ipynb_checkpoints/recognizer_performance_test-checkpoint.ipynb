{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "18ce0100-e535-4872-bdf0-66f3b0c38434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "92f9eaad-639d-4d28-8391-391af61613fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce GTX 1080 Ti\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"runs/detect/train4/weights/best.pt\"\n",
    "recognition_model = YOLO(model_path)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.device(\"cuda\"))\n",
    "device = torch.device(\"cuda\")\n",
    "recognition_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e4b4f91-3b17-4cb9-a204-015f9b3d2f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU: 0.14285714285663267\n"
     ]
    }
   ],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    - box1: Tuple or List representing (x1, y1, x2, y2) of the first box.\n",
    "    - box2: Tuple or List representing (x1, y1, x2, y2) of the second box.\n",
    "\n",
    "    Returns:\n",
    "    - IoU: Intersection over Union.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract coordinates\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "\n",
    "    # Calculate intersection coordinates\n",
    "    x_intersection = max(0, min(x2_1, x2_2) - max(x1_1, x1_2))\n",
    "    y_intersection = max(0, min(y2_1, y2_2) - max(y1_1, y1_2))\n",
    "\n",
    "    # Calculate areas of boxes and intersection\n",
    "    area_box1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    area_box2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    area_intersection = x_intersection * y_intersection\n",
    "\n",
    "    # Calculate Union\n",
    "    area_union = area_box1 + area_box2 - area_intersection\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = area_intersection / (area_union + 1e-10)  # Add a small epsilon to avoid division by zero\n",
    "\n",
    "    return iou\n",
    "\n",
    "# Example usage:\n",
    "box1 = (0, 0, 4, 4)\n",
    "box2 = (2, 2, 6, 6)\n",
    "\n",
    "iou = calculate_iou(box1, box2)\n",
    "print(f\"IoU: {iou}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc4580-af79-4b74-be33-6e14ecf77022",
   "metadata": {},
   "source": [
    "## testing whitout preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "aac3c6b4-a6b8-4fc5-a398-a3da5afebcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.368409156799316. Dividing input by 255.\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "overal_digits = 0\n",
    "overal_predicted_digits = 0\n",
    "overal_correct_digits = 0\n",
    "overal_numbers = 0\n",
    "overal_correct_numbers = 0\n",
    "with open('test_results_no_preprocess.csv', 'w', newline='') as csv_file:\n",
    "\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    rep = 0\n",
    "    dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = recognition_model(dummy_input)\n",
    "    timings = []\n",
    "\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    field = [\"filename\", \"backnumber\",\"predicted_number\", \"amount_of_numbers\",\"digits_predicted\", \"number_predicted_correct\", \"number_of_predicted_digits\", \"inference_time\"]\n",
    "    writer.writerow(field)\n",
    "    progress = 0\n",
    "    for file in os.listdir(os.path.join('datasets','test', 'images')):\n",
    "\n",
    "        \n",
    "        img = cv2.imread(os.path.join('datasets','test','images', file))\n",
    "        starter.record()\n",
    "        results = recognition_model(img, verbose=False)\n",
    "        ender.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings.append(curr_time)\n",
    "        predicted_digits = []\n",
    "        average_x = []\n",
    "        result = results[0].boxes\n",
    "        digits_to_discard = []\n",
    "        boxes = []\n",
    "        for i in range(len(result.cls)):\n",
    "            for j in range(i+1, len(result.cls)):\n",
    "                box1 = (result.xyxy[i][0].item(), result.xyxy[i][1].item(), result.xyxy[i][2].item(), result.xyxy[i][3].item())\n",
    "                box2 = (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item())\n",
    "                iou = calculate_iou(box1, box2)\n",
    "                if iou > 0.5:\n",
    "                    if result.conf[i].item() > result.conf[j].item():\n",
    "                        digits_to_discard.append(j)\n",
    "                    else:\n",
    "                        digits_to_discard.append(i)\n",
    "                    \n",
    "        for j in range(len(result.cls)):\n",
    "            if j not in digits_to_discard:\n",
    "                predicted_digits.append(int(result.cls[j].item()))\n",
    "                boxes.append( (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item()))\n",
    "                average_x.append((result.xyxy[j][2].item()+result.xyxy[j][0].item())/2)\n",
    "            \n",
    "        predicted_digits = [x for _,x in sorted(zip(average_x,predicted_digits))]\n",
    "        predicted_boxes = [x for _,x in sorted(zip(average_x,boxes))]\n",
    "        predicted_number =\"\".join([str(i) for i in predicted_digits])\n",
    "        \n",
    "        filename = file.split('.')[0] +'.' + file.split('.')[1] +'.txt'\n",
    "        existing_filepath = os.path.join('datasets','test','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            # Using readlines()\n",
    "            file1 = open(existing_filepath, 'r')\n",
    "            Lines = file1.readlines()\n",
    "            boxes = []\n",
    "            count = 0\n",
    "            number = ''\n",
    "            digits = []\n",
    "            average_x = []\n",
    "            height, width, _ = img.shape\n",
    "            # Strips the newline character\n",
    "            for line in Lines:\n",
    "                count += 1\n",
    "                digits.append(line.split(' ')[0])\n",
    "                average_x.append(line.split(' ')[1])\n",
    "                box = ((float(line.split(' ')[1]) - float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) - float(line.split(' ')[4])/2)*height, (float(line.split(' ')[1]) + float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) + float(line.split(' ')[4])/2)*height)\n",
    "                boxes.append(box)\n",
    "            digits = [x for _, x in sorted(zip(average_x, digits))]\n",
    "            boxes = [x for _, x in sorted(zip(average_x, boxes))]\n",
    "            number =\"\".join([str(i) for i in digits])\n",
    "            correctly_predicted_digits = 0\n",
    "            already_found = []\n",
    "            for i in range(len(predicted_digits)):\n",
    "                for j in range(len(digits)):\n",
    "                    if j not in already_found:\n",
    "                        if calculate_iou(predicted_boxes[i], boxes[j]) >0.5:\n",
    "                            if predicted_digits[i] == int(digits[j]):\n",
    "                                correctly_predicted_digits += 1\n",
    "                                already_found.append(j)\n",
    "\n",
    "            overal_digits+= count\n",
    "            overal_numbers+= 1\n",
    "            overal_predicted_digits += len(predicted_digits)\n",
    "            overal_correct_digits += correctly_predicted_digits\n",
    "            if number == predicted_number:\n",
    "                overal_correct_numbers += 1\n",
    "            field = [filename, number,predicted_number, str(count), correctly_predicted_digits,number == predicted_number, predicted_digits, curr_time]\n",
    "            writer.writerow(field)\n",
    "            progress+=1\n",
    "        if progress % 500 == 0:\n",
    "            print(progress)\n",
    "        \"\"\"if progress >1:\n",
    "            break\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "71ad1bb7-2858-49ef-945d-5d576df56053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of digits in the testing dataset: 13920\n",
      "the number of digits that where predicted: 11915\n",
      "the digits that were predicted correctly: 10082\n",
      "the amount of numbers that were evaluated: 6000\n",
      "the numbers that werepredicted correct entirely: 3284\n",
      "average inference time: 18.53888016732534\n"
     ]
    }
   ],
   "source": [
    "print(f'the total number of digits in the testing dataset: {overal_digits}')\n",
    "print(f'the number of digits that where predicted: {overal_predicted_digits}')\n",
    "print(f'the digits that were predicted correctly: {overal_correct_digits}')\n",
    "print(f'the amount of numbers that were evaluated: {overal_numbers}')\n",
    "print(f'the numbers that werepredicted correct entirely: {overal_correct_numbers}')\n",
    "print(f'average inference time: {np.sum(np.array(timings))/len(timings)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4869cfc-adbe-442a-88f7-0ffe54768f02",
   "metadata": {},
   "source": [
    "## testing with preprocessing, watershed based, perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adfa95f9-698d-46c4-adda-59e37765739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5cc2edc2-6f2b-41eb-bb97-5b5c6d0e9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners(cnt):\n",
    "    \n",
    "    def find_closest(edge):\n",
    "        min_dist = np.inf\n",
    "        closest = [0,0]\n",
    "        for point in cnt:\n",
    "            dist = (edge[0]-point[0][0])**2+(edge[1]-point[0][1])**2\n",
    "            if dist<min_dist:\n",
    "                min_dist = dist\n",
    "                closest = point[0]\n",
    "        return closest\n",
    "            \n",
    "    def order_corner_points(corners):\n",
    "        # Separate corners into individual points\n",
    "        # Index 0 - top-right\n",
    "        #       1 - top-left\n",
    "        #       2 - bottom-left\n",
    "        #       3 - bottom-right\n",
    "        nr = len(corners)\n",
    "        if nr != 4:\n",
    "            return []\n",
    "        corners = np.array([[corner[0][0], corner[0][1]] for corner in corners])\n",
    "        average_x = corners[:,0].sum()/nr\n",
    "        average_y =  corners[:,1].sum()/nr\n",
    "        top_l, top_r, bottom_r, bottom_l = [None, None], [None, None],[None, None],[None, None]\n",
    "        for corner in corners:\n",
    "            if corner[1]<average_y:\n",
    "                if corner[0] < average_x:\n",
    "                    top_l = corner\n",
    "                else:\n",
    "                    top_r = corner\n",
    "            else:\n",
    "                if corner[0] < average_x:\n",
    "                    bottom_l = corner\n",
    "                else:\n",
    "                    bottom_r = corner\n",
    "        corners = []\n",
    "        if top_l[0] != None:\n",
    "            #find point closest to [0,0]\n",
    "            #top_l = find_closest([0,0])\n",
    "            top_l[1] = top_l[1]-10 if top_l[1]-10>0 else 0\n",
    "            top_l[0] = top_l[0]-10 if top_l[0]-10>0 else 0\n",
    "            corners.append(top_l)\n",
    "        if top_r[0] != None:\n",
    "            #find point closest to [cnt.shape[1]-1,0]\n",
    "            #top_r = find_closest([original.shape[1]-1,0])\n",
    "            top_r[1] = top_r[1]-10 if top_r[1]-10>0 else 0\n",
    "            top_r[0] = top_r[0]+10 if top_r[0]+10 < original.shape[1] else original.shape[1]-1\n",
    "            corners.append(top_r)\n",
    "        if bottom_r[0] != None:\n",
    "            #find point closest to [cnt.shape[1]-1,cnt.shape[0]-1]\n",
    "            #bottom_r= find_closest([original.shape[1]-1,original.shape[0]-1])\n",
    "            corners.append(bottom_r)\n",
    "        if bottom_l[0] != None:\n",
    "            #find point closest to [0,cnt.shape[0]-1]\n",
    "            #bottom_l= find_closest([0,original.shape[0]-1])\n",
    "            corners.append(bottom_l)\n",
    "\n",
    "        \"\"\"top_l[1] = top_l[1]-10 if top_l[1]-10>0 else 0\n",
    "        top_r[1] = top_r[1]-10 if top_r[1]-10>0 else 0\n",
    "        top_l[0] = top_l[0]-10 if top_l[0]-10>0 else 0\n",
    "        top_r[0] = top_r[0]+10 if top_r[0]+10 < original.shape[1] else original.shape[1]-1\n",
    "        return (top_l, top_r, bottom_r, bottom_l)\"\"\"\n",
    "        return corners\n",
    "    \n",
    "    \n",
    "    epsilon = 0.06 * cv.arcLength(cnt, True)\n",
    "    approx_corners = cv.approxPolyDP(cnt, epsilon, True)\n",
    "    corners = order_corner_points(approx_corners)\n",
    "    canvas = np.zeros((original.shape[0],original.shape[1],3), np.uint8)\n",
    "    cv.drawContours(canvas, cnt, -1, (0, 255, 255))\n",
    "    plt.imshow(canvas)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78364b87-460b-4f60-ae9e-676e88983bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_thresh(img):\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv.threshold(gray,217,255,cv.THRESH_BINARY)\n",
    "    \n",
    "    \n",
    "    # noise removal\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 1)\n",
    "    # sure background area\n",
    "    sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "    ret, sure_fg = cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv.subtract(sure_bg,sure_fg)\n",
    "    canvas = np.zeros((img.shape[0],img.shape[1],3), np.uint8)\n",
    "    contours, hierarchy = cv.findContours(unknown, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    if len(contours) != 0:\n",
    "        cnt = sorted(contours, key=cv.contourArea, reverse=True)[0]\n",
    "        cv.drawContours(canvas, cnt, -1, (0, 255, 255))\n",
    "        return cnt\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4db8a80-a0d0-45ec-9857-52c0e1784977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image, corners):\n",
    "\n",
    "    \n",
    "    top_l, top_r, bottom_r, bottom_l = corners\n",
    "    \n",
    "    ordered_corners = (top_l, top_r, bottom_r, bottom_l)\n",
    "\n",
    "    # Determine width of new image which is the max distance between \n",
    "    # (bottom right and bottom left) or (top right and top left) x-coordinates\n",
    "    width_A = np.sqrt(((bottom_r[0] - bottom_l[0]) ** 2) + ((bottom_r[1] - bottom_l[1]) ** 2))\n",
    "    width_B = np.sqrt(((top_r[0] - top_l[0]) ** 2) + ((top_r[1] - top_l[1]) ** 2))\n",
    "    width = max(int(width_A), int(width_B))\n",
    "\n",
    "    # Determine height of new image which is the max distance between \n",
    "    # (top right and bottom right) or (top left and bottom left) y-coordinates\n",
    "    height_A = np.sqrt(((top_r[0] - bottom_r[0]) ** 2) + ((top_r[1] - bottom_r[1]) ** 2))\n",
    "    height_B = np.sqrt(((top_l[0] - bottom_l[0]) ** 2) + ((top_l[1] - bottom_l[1]) ** 2))\n",
    "    height = max(int(height_A), int(height_B))\n",
    "\n",
    "    # Construct new points to obtain top-down view of image in \n",
    "    # top_r, top_l, bottom_l, bottom_r order\n",
    "    dimensions = np.array([[0, 0], [width - 1,0], [width - 1 , height - 1], \n",
    "                    [0,height - 1]], dtype = \"float32\")\n",
    "\n",
    "    # Convert to Numpy format\n",
    "    ordered_corners = np.array(ordered_corners, dtype=\"float32\")\n",
    "\n",
    "    # Find perspective transform matrix\n",
    "    matrix = cv.getPerspectiveTransform(ordered_corners, dimensions)\n",
    "    # Transform the image\n",
    "    transformed = cv.warpPerspective(image, matrix, (width, height),flags=cv.INTER_NEAREST,borderMode=cv.BORDER_REPLICATE)\n",
    "    \n",
    "    \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "794c6e89-80c3-4a42-a292-2c491c4e1d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.078889846801758. Dividing input by 255.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'approx_corners' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m cnt \u001b[38;5;241m=\u001b[39m get_contours_thresh(img_copy)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cnt)\u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     corners \u001b[38;5;241m=\u001b[39m \u001b[43mget_corners\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(corners) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m     32\u001b[0m         img \u001b[38;5;241m=\u001b[39m perspective_transform(original, corners)\n",
      "Cell \u001b[0;32mIn[114], line 48\u001b[0m, in \u001b[0;36mget_corners\u001b[0;34m(cnt)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"top_l[1] = top_l[1]-10 if top_l[1]-10>0 else 0\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    top_r[1] = top_r[1]-10 if top_r[1]-10>0 else 0\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    top_l[0] = top_l[0]-10 if top_l[0]-10>0 else 0\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    top_r[0] = top_r[0]+10 if top_r[0]+10 < original.shape[1] else original.shape[1]-1\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    return (top_l, top_r, bottom_r, bottom_l)\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m corners\n\u001b[0;32m---> 48\u001b[0m corners \u001b[38;5;241m=\u001b[39m order_corner_points(\u001b[43mapprox_corners\u001b[49m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m corners\n",
      "\u001b[0;31mNameError\u001b[0m: name 'approx_corners' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "overal_digits = 0\n",
    "overal_predicted_digits = 0\n",
    "overal_correct_digits = 0\n",
    "overal_numbers = 0\n",
    "overal_correct_numbers = 0\n",
    "with open('test_results_watershed_perspective.csv', 'w', newline='') as csv_file:\n",
    "\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    rep = 0\n",
    "    dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = recognition_model(dummy_input)\n",
    "    timings = []\n",
    "\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    field = [\"filename\", \"backnumber\",\"predicted_number\", \"amount_of_numbers\",\"digits_predicted\", \"number_predicted_correct\", \"number_of_predicted_digits\", \"inference_time\"]\n",
    "    writer.writerow(field)\n",
    "    progress = 0\n",
    "    for file in os.listdir(os.path.join('datasets','test', 'images')):\n",
    "\n",
    "        \n",
    "        img = cv2.imread(os.path.join('datasets','test','images', file))\n",
    "        original = np.copy(img)\n",
    "        img_copy = np.copy(img)\n",
    "        starter.record()\n",
    "        cnt = get_contours_thresh(img_copy)\n",
    "        if len(cnt)!= 0:\n",
    "            corners = get_corners(cnt)\n",
    "            if len(corners) <= 4:\n",
    "                img = perspective_transform(original, corners)\n",
    "        results = recognition_model(img, verbose=False)\n",
    "        ender.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings.append(curr_time)\n",
    "        predicted_digits = []\n",
    "        average_x = []\n",
    "        result = results[0].boxes\n",
    "        digits_to_discard = []\n",
    "        boxes = []\n",
    "        for i in range(len(result.cls)):\n",
    "            for j in range(i+1, len(result.cls)):\n",
    "                box1 = (result.xyxy[i][0].item(), result.xyxy[i][1].item(), result.xyxy[i][2].item(), result.xyxy[i][3].item())\n",
    "                box2 = (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item())\n",
    "                iou = calculate_iou(box1, box2)\n",
    "                if iou > 0.5:\n",
    "                    if result.conf[i].item() > result.conf[j].item():\n",
    "                        digits_to_discard.append(j)\n",
    "                    else:\n",
    "                        digits_to_discard.append(i)\n",
    "                    \n",
    "        for j in range(len(result.cls)):\n",
    "            if j not in digits_to_discard:\n",
    "                predicted_digits.append(int(result.cls[j].item()))\n",
    "                boxes.append( (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item()))\n",
    "                average_x.append((result.xyxy[j][2].item()+result.xyxy[j][0].item())/2)\n",
    "            \n",
    "        predicted_digits = [x for _,x in sorted(zip(average_x,predicted_digits))]\n",
    "        predicted_boxes = [x for _,x in sorted(zip(average_x,boxes))]\n",
    "        predicted_number =\"\".join([str(i) for i in predicted_digits])\n",
    "        \n",
    "        filename = file.split('.')[0] +'.' + file.split('.')[1] +'.txt'\n",
    "        existing_filepath = os.path.join('datasets','test','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            # Using readlines()\n",
    "            file1 = open(existing_filepath, 'r')\n",
    "            Lines = file1.readlines()\n",
    "            boxes = []\n",
    "            count = 0\n",
    "            number = ''\n",
    "            digits = []\n",
    "            average_x = []\n",
    "            height, width, _ = img.shape\n",
    "            # Strips the newline character\n",
    "            for line in Lines:\n",
    "                count += 1\n",
    "                digits.append(line.split(' ')[0])\n",
    "                average_x.append(line.split(' ')[1])\n",
    "                box = ((float(line.split(' ')[1]) - float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) - float(line.split(' ')[4])/2)*height, (float(line.split(' ')[1]) + float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) + float(line.split(' ')[4])/2)*height)\n",
    "                boxes.append(box)\n",
    "            digits = [x for _, x in sorted(zip(average_x, digits))]\n",
    "            boxes = [x for _, x in sorted(zip(average_x, boxes))]\n",
    "            number =\"\".join([str(i) for i in digits])\n",
    "            correctly_predicted_digits = 0\n",
    "            \"\"\"already_found = []\n",
    "            for i in range(len(predicted_digits)):\n",
    "                for j in range(len(digits)):\n",
    "                    if j not in already_found:\n",
    "                        if calculate_iou(predicted_boxes[i], boxes[j]) >0.5:\n",
    "                            if predicted_digits[i] == int(digits[j]):\n",
    "                                correctly_predicted_digits += 1\n",
    "                                already_found.append(j)\"\"\"\n",
    "\n",
    "            overal_digits+= count\n",
    "            overal_numbers+= 1\n",
    "            overal_predicted_digits += len(predicted_digits)\n",
    "            overal_correct_digits += correctly_predicted_digits\n",
    "            if number == predicted_number:\n",
    "                overal_correct_numbers += 1\n",
    "            field = [filename, number,predicted_number, str(count), correctly_predicted_digits,number == predicted_number, predicted_digits, curr_time]\n",
    "            writer.writerow(field)\n",
    "            progress+=1\n",
    "        if progress % 500 == 0:\n",
    "            print(progress)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "81442feb-05e0-45bc-ad8c-a15fc031f208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of digits in the testing dataset: 13920\n",
      "the number of digits that where predicted: 6240\n",
      "the digits that were predicted correctly: 0\n",
      "the amount of numbers that were evaluated: 6000\n",
      "the numbers that werepredicted correct entirely: 1550\n",
      "average inference time: 22.303172561327617\n"
     ]
    }
   ],
   "source": [
    "print(f'the total number of digits in the testing dataset: {overal_digits}')\n",
    "print(f'the number of digits that where predicted: {overal_predicted_digits}')\n",
    "print(f'the digits that were predicted correctly: {overal_correct_digits}')\n",
    "print(f'the amount of numbers that were evaluated: {overal_numbers}')\n",
    "print(f'the numbers that werepredicted correct entirely: {overal_correct_numbers}')\n",
    "print(f'average inference time: {np.sum(np.array(timings))/len(timings)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45257f3-348d-4b97-a5de-4325751e740a",
   "metadata": {},
   "source": [
    "## now use homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e0cac6e4-7281-4ec2-9fa4-c1bbd4f609ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwarp(img, src):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img: np.array\n",
    "        src: list\n",
    "        dst: list\n",
    "    Returns:\n",
    "        un_warped: np.array\n",
    "    \"\"\"\n",
    "    h,w,_ = img.shape\n",
    "    top_l, top_r, bottom_r, bottom_l = src\n",
    "    \n",
    "    ordered_corners = (top_l, top_r, bottom_r, bottom_l)\n",
    "\n",
    "    # Determine width of new image which is the max distance between \n",
    "    # (bottom right and bottom left) or (top right and top left) x-coordinates\n",
    "    width_A = np.sqrt(((bottom_r[0] - bottom_l[0]) ** 2) + ((bottom_r[1] - bottom_l[1]) ** 2))\n",
    "    width_B = np.sqrt(((top_r[0] - top_l[0]) ** 2) + ((top_r[1] - top_l[1]) ** 2))\n",
    "    width = max(int(width_A), int(width_B))\n",
    "\n",
    "    # Determine height of new image which is the max distance between \n",
    "    # (top right and bottom right) or (top left and bottom left) y-coordinates\n",
    "    height_A = np.sqrt(((top_r[0] - bottom_r[0]) ** 2) + ((top_r[1] - bottom_r[1]) ** 2))\n",
    "    height_B = np.sqrt(((top_l[0] - bottom_l[0]) ** 2) + ((top_l[1] - bottom_l[1]) ** 2))\n",
    "    height = max(int(height_A), int(height_B))\n",
    "\n",
    "    # Construct new points to obtain top-down view of image in \n",
    "    # top_r, top_l, bottom_l, bottom_r order\n",
    "    dimensions = np.array([[w//10, h//10], [w - w//10,0],[0,h - h//10], [w - w//10 , h - h//10]\n",
    "                    ], dtype = \"float32\")\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    H, _ = cv.findHomography(np.array([top_l,  top_r, bottom_l, bottom_r]), dimensions, method=cv.RANSAC, ransacReprojThreshold=3.0)\n",
    "    \n",
    "    un_warped = cv.warpPerspective(img, H, (w, h), flags=cv.INTER_LINEAR)\n",
    "\n",
    "    # plot\n",
    "    return un_warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "27df54f7-a52c-4b4d-9eb0-9b3c5ae71ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.292972564697266. Dividing input by 255.\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "overal_digits = 0\n",
    "overal_predicted_digits = 0\n",
    "overal_correct_digits = 0\n",
    "overal_numbers = 0\n",
    "overal_correct_numbers = 0\n",
    "with open('test_results_watershed_homography.csv', 'w', newline='') as csv_file:\n",
    "\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    rep = 0\n",
    "    dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = recognition_model(dummy_input)\n",
    "    timings = []\n",
    "\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    field = [\"filename\", \"backnumber\",\"predicted_number\", \"amount_of_numbers\",\"digits_predicted\", \"number_predicted_correct\", \"number_of_predicted_digits\", \"inference_time\"]\n",
    "    writer.writerow(field)\n",
    "    progress = 0\n",
    "    for file in os.listdir(os.path.join('datasets','test', 'images')):\n",
    "\n",
    "        \n",
    "        img = cv2.imread(os.path.join('datasets','test','images', file))\n",
    "        original = np.copy(img)\n",
    "        img_copy = np.copy(img)\n",
    "        starter.record()\n",
    "        cnt = get_contours_thresh(img_copy)\n",
    "        if len(cnt)!= 0:\n",
    "            corners = get_corners(cnt)\n",
    "            if len(corners) <= 4:\n",
    "                img = unwarp(original, corners)\n",
    "        results = recognition_model(img, verbose=False)\n",
    "        ender.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings.append(curr_time)\n",
    "        predicted_digits = []\n",
    "        average_x = []\n",
    "        result = results[0].boxes\n",
    "        digits_to_discard = []\n",
    "        boxes = []\n",
    "        for i in range(len(result.cls)):\n",
    "            for j in range(i+1, len(result.cls)):\n",
    "                box1 = (result.xyxy[i][0].item(), result.xyxy[i][1].item(), result.xyxy[i][2].item(), result.xyxy[i][3].item())\n",
    "                box2 = (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item())\n",
    "                iou = calculate_iou(box1, box2)\n",
    "                if iou > 0.5:\n",
    "                    if result.conf[i].item() > result.conf[j].item():\n",
    "                        digits_to_discard.append(j)\n",
    "                    else:\n",
    "                        digits_to_discard.append(i)\n",
    "                    \n",
    "        for j in range(len(result.cls)):\n",
    "            if j not in digits_to_discard:\n",
    "                predicted_digits.append(int(result.cls[j].item()))\n",
    "                boxes.append( (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item()))\n",
    "                average_x.append((result.xyxy[j][2].item()+result.xyxy[j][0].item())/2)\n",
    "            \n",
    "        predicted_digits = [x for _,x in sorted(zip(average_x,predicted_digits))]\n",
    "        predicted_boxes = [x for _,x in sorted(zip(average_x,boxes))]\n",
    "        predicted_number =\"\".join([str(i) for i in predicted_digits])\n",
    "\n",
    "        \n",
    "        filename = file.split('.')[0] +'.' + file.split('.')[1] +'.txt'\n",
    "        existing_filepath = os.path.join('datasets','test','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            # Using readlines()\n",
    "            file1 = open(existing_filepath, 'r')\n",
    "            Lines = file1.readlines()\n",
    "            boxes = []\n",
    "            count = 0\n",
    "            number = ''\n",
    "            digits = []\n",
    "            average_x = []\n",
    "            height, width, _ = img.shape\n",
    "            # Strips the newline character\n",
    "            for line in Lines:\n",
    "                count += 1\n",
    "                digits.append(line.split(' ')[0])\n",
    "                average_x.append(line.split(' ')[1])\n",
    "                box = ((float(line.split(' ')[1]) - float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) - float(line.split(' ')[4])/2)*height, (float(line.split(' ')[1]) + float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) + float(line.split(' ')[4])/2)*height)\n",
    "                boxes.append(box)\n",
    "            digits = [x for _, x in sorted(zip(average_x, digits))]\n",
    "            boxes = [x for _, x in sorted(zip(average_x, boxes))]\n",
    "            number =\"\".join([str(i) for i in digits])\n",
    "            correctly_predicted_digits = 0\n",
    "            already_found = []\n",
    "            \"\"\"for i in range(len(predicted_digits)):\n",
    "                for j in range(len(digits)):\n",
    "                    if j not in already_found:\n",
    "                        if calculate_iou(predicted_boxes[i], boxes[j]) >0.5:\n",
    "                            if predicted_digits[i] == int(digits[j]):\n",
    "                                correctly_predicted_digits += 1\n",
    "                                already_found.append(j)\"\"\"\n",
    "\n",
    "            overal_digits+= count\n",
    "            overal_numbers+= 1\n",
    "            overal_predicted_digits += len(predicted_digits)\n",
    "            overal_correct_digits += correctly_predicted_digits\n",
    "            if number == predicted_number:\n",
    "                overal_correct_numbers += 1\n",
    "            field = [filename, number,predicted_number, str(count), correctly_predicted_digits,number == predicted_number, predicted_digits, curr_time]\n",
    "            writer.writerow(field)\n",
    "            progress+=1\n",
    "\n",
    "        if progress % 500 == 0:\n",
    "            print(progress)\n",
    "        \"\"\"if progress >1:\n",
    "            break\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9aa32016-c0f4-47fe-9dee-bd0d175195d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of digits in the testing dataset: 13920\n",
      "the number of digits that where predicted: 7170\n",
      "the digits that were predicted correctly: 0\n",
      "the amount of numbers that were evaluated: 6000\n",
      "the numbers that werepredicted correct entirely: 1759\n",
      "average inference time: 22.622637280464172\n"
     ]
    }
   ],
   "source": [
    "print(f'the total number of digits in the testing dataset: {overal_digits}')\n",
    "print(f'the number of digits that where predicted: {overal_predicted_digits}')\n",
    "print(f'the digits that were predicted correctly: {overal_correct_digits}')\n",
    "print(f'the amount of numbers that were evaluated: {overal_numbers}')\n",
    "print(f'the numbers that werepredicted correct entirely: {overal_correct_numbers}')\n",
    "print(f'average inference time: {np.sum(np.array(timings))/len(timings)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bb13d0-1522-498b-8096-e6300ccad475",
   "metadata": {},
   "source": [
    "## now use kmeans first with perspective\n",
    "try later to use https://www.blog.dailydoseofds.com/p/make-sklearn-kmeans-20x-times-faster \\\n",
    "or try kmeans gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fd41ef0d-32d0-4bbd-93bf-3f2f727be42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# can initialize kmeans one time so don't add to time\n",
    "kmeans=KMeans(n_clusters=10, n_init=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f93f12c9-9366-4b97-8c84-c060d10d5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_kmeans(img):\n",
    "    original  = img.copy()\n",
    "    img=img.reshape((img.shape[1]*img.shape[0],3))\n",
    "    s=kmeans.fit(img)\n",
    "    labels=kmeans.labels_\n",
    "    centroid=kmeans.cluster_centers_\n",
    "    \n",
    "    good_labels = []\n",
    "    for i in range(len(centroid)):\n",
    "        if centroid[i].max() - centroid[i].min() <35 and centroid[i].min()>155:\n",
    "            good_labels.append(i)\n",
    "    mask = np.zeros(len(labels), dtype = np.uint8)\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] in good_labels:\n",
    "            mask[i] = 255\n",
    "    mask = mask.reshape((original.shape[0],original.shape[1]))\n",
    "    contours, hierarchy = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    if len(contours) != 0:\n",
    "        cnt = sorted(contours, key=cv.contourArea, reverse=True)[0]\n",
    "        \n",
    "        return cnt\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "49928fd0-7957-4747-ae4c-dff7d5115152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "55684be1-0cd6-48a2-a08a-9f4e9811adab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a1909e45-3261-488c-ae66-7ab12698b94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.2055864334106445. Dividing input by 255.\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "overal_digits = 0\n",
    "overal_predicted_digits = 0\n",
    "overal_correct_digits = 0\n",
    "overal_numbers = 0\n",
    "overal_correct_numbers = 0\n",
    "with open('test_results_kmeans_perspective.csv', 'w', newline='') as csv_file:\n",
    "\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    rep = 0\n",
    "    dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = recognition_model(dummy_input)\n",
    "    timings = []\n",
    "\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    field = [\"filename\", \"backnumber\",\"predicted_number\", \"amount_of_numbers\",\"digits_predicted\", \"number_predicted_correct\", \"number_of_predicted_digits\", \"inference_time\"]\n",
    "    writer.writerow(field)\n",
    "    progress = 0\n",
    "    for file in os.listdir(os.path.join('datasets','test', 'images')):\n",
    "\n",
    "        \n",
    "        img = cv2.imread(os.path.join('datasets','test','images', file))\n",
    "        original = np.copy(img)\n",
    "        img_copy = np.copy(img)\n",
    "        starter.record()\n",
    "        #start_time = time.time()\n",
    "        cnt = get_contours_kmeans_alt(img_copy)\n",
    "        if len(cnt)!= 0:\n",
    "            corners = get_corners_alt(cnt, original)\n",
    "            if len(corners) == 4:\n",
    "                img = perspective_transform(original, corners)\n",
    "        #print(\"My program took\", time.time() - start_time, \"to run\")\n",
    "        results = recognition_model(img, verbose=False)\n",
    "        ender.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings.append(curr_time)\n",
    "        predicted_digits = []\n",
    "        average_x = []\n",
    "        result = results[0].boxes\n",
    "        digits_to_discard = []\n",
    "        boxes = []\n",
    "        for i in range(len(result.cls)):\n",
    "            for j in range(i+1, len(result.cls)):\n",
    "                box1 = (result.xyxy[i][0].item(), result.xyxy[i][1].item(), result.xyxy[i][2].item(), result.xyxy[i][3].item())\n",
    "                box2 = (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item())\n",
    "                iou = calculate_iou(box1, box2)\n",
    "                if iou > 0.5:\n",
    "                    if result.conf[i].item() > result.conf[j].item():\n",
    "                        digits_to_discard.append(j)\n",
    "                    else:\n",
    "                        digits_to_discard.append(i)\n",
    "                    \n",
    "        for j in range(len(result.cls)):\n",
    "            if j not in digits_to_discard:\n",
    "                predicted_digits.append(int(result.cls[j].item()))\n",
    "                boxes.append( (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item()))\n",
    "                average_x.append((result.xyxy[j][2].item()+result.xyxy[j][0].item())/2)\n",
    "            \n",
    "        predicted_digits = [x for _,x in sorted(zip(average_x,predicted_digits))]\n",
    "        predicted_boxes = [x for _,x in sorted(zip(average_x,boxes))]\n",
    "        predicted_number =\"\".join([str(i) for i in predicted_digits])\n",
    "        \n",
    "        filename = file.split('.')[0] +'.' + file.split('.')[1] +'.txt'\n",
    "        existing_filepath = os.path.join('datasets','test','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            # Using readlines()\n",
    "            file1 = open(existing_filepath, 'r')\n",
    "            Lines = file1.readlines()\n",
    "            boxes = []\n",
    "            count = 0\n",
    "            number = ''\n",
    "            digits = []\n",
    "            average_x = []\n",
    "            height, width, _ = img.shape\n",
    "            # Strips the newline character\n",
    "            for line in Lines:\n",
    "                count += 1\n",
    "                digits.append(line.split(' ')[0])\n",
    "                average_x.append(line.split(' ')[1])\n",
    "                box = ((float(line.split(' ')[1]) - float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) - float(line.split(' ')[4])/2)*height, (float(line.split(' ')[1]) + float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) + float(line.split(' ')[4])/2)*height)\n",
    "                boxes.append(box)\n",
    "            digits = [x for _, x in sorted(zip(average_x, digits))]\n",
    "            boxes = [x for _, x in sorted(zip(average_x, boxes))]\n",
    "            number =\"\".join([str(i) for i in digits])\n",
    "            correctly_predicted_digits = 0\n",
    "            already_found = []\n",
    "            \"\"\"for i in range(len(predicted_digits)):\n",
    "                for j in range(len(digits)):\n",
    "                    if j not in already_found:\n",
    "                        if calculate_iou(predicted_boxes[i], boxes[j]) >0.5:\n",
    "                            if predicted_digits[i] == int(digits[j]):\n",
    "                                correctly_predicted_digits += 1\n",
    "                                already_found.append(j)\"\"\"\n",
    "\n",
    "            overal_digits+= count\n",
    "            overal_numbers+= 1\n",
    "            overal_predicted_digits += len(predicted_digits)\n",
    "            overal_correct_digits += correctly_predicted_digits\n",
    "            if number == predicted_number:\n",
    "                overal_correct_numbers += 1\n",
    "            field = [filename, number,predicted_number, str(count), correctly_predicted_digits,number == predicted_number, predicted_digits, curr_time]\n",
    "            writer.writerow(field)\n",
    "            progress+=1\n",
    "        if progress % 500 == 0:\n",
    "            print(progress)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ea1533cb-0810-4a1f-bb19-84054d4720d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of digits in the testing dataset: 13920\n",
      "the number of digits that where predicted: 11394\n",
      "the digits that were predicted correctly: 0\n",
      "the amount of numbers that were evaluated: 6000\n",
      "the numbers that werepredicted correct entirely: 2891\n",
      "average inference time: 348.40166172981264\n"
     ]
    }
   ],
   "source": [
    "print(f'the total number of digits in the testing dataset: {overal_digits}')\n",
    "print(f'the number of digits that where predicted: {overal_predicted_digits}')\n",
    "print(f'the digits that were predicted correctly: {overal_correct_digits}')\n",
    "print(f'the amount of numbers that were evaluated: {overal_numbers}')\n",
    "print(f'the numbers that werepredicted correct entirely: {overal_correct_numbers}')\n",
    "print(f'average inference time: {np.sum(np.array(timings))/len(timings)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57bbb9-de33-4c0d-b250-9d3c92768441",
   "metadata": {},
   "source": [
    "## now use homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175458b0-82ea-447f-8cb2-36fe7be4e21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.678465843200684. Dividing input by 255.\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "overal_digits = 0\n",
    "overal_predicted_digits = 0\n",
    "overal_correct_digits = 0\n",
    "overal_numbers = 0\n",
    "overal_correct_numbers = 0\n",
    "with open('test_results_kmeans_homography.csv', 'w', newline='') as csv_file:\n",
    "\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    rep = 0\n",
    "    dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = recognition_model(dummy_input)\n",
    "    timings = []\n",
    "\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    field = [\"filename\", \"backnumber\",\"predicted_number\", \"amount_of_numbers\",\"digits_predicted\", \"number_predicted_correct\", \"number_of_predicted_digits\", \"inference_time\"]\n",
    "    writer.writerow(field)\n",
    "    progress = 0\n",
    "    for file in os.listdir(os.path.join('datasets','test', 'images')):\n",
    "\n",
    "        \n",
    "        img = cv2.imread(os.path.join('datasets','test','images', file))\n",
    "        original = np.copy(img)\n",
    "        img_copy = np.copy(img)\n",
    "        starter.record()\n",
    "        #start_time = time.time()\n",
    "        cnt = get_contours_kmeans_alt(img_copy)\n",
    "        if len(cnt)!= 0:\n",
    "            corners = get_corners_alt(cnt, original)\n",
    "            if len(corners) == 4:\n",
    "                img = unwarp(original, corners)\n",
    "        #print(\"My program took\", time.time() - start_time, \"to run\")\n",
    "        results = recognition_model(img, verbose=False)\n",
    "        ender.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings.append(curr_time)\n",
    "        predicted_digits = []\n",
    "        average_x = []\n",
    "        result = results[0].boxes\n",
    "        digits_to_discard = []\n",
    "        boxes = []\n",
    "        for i in range(len(result.cls)):\n",
    "            for j in range(i+1, len(result.cls)):\n",
    "                box1 = (result.xyxy[i][0].item(), result.xyxy[i][1].item(), result.xyxy[i][2].item(), result.xyxy[i][3].item())\n",
    "                box2 = (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item())\n",
    "                iou = calculate_iou(box1, box2)\n",
    "                if iou > 0.5:\n",
    "                    if result.conf[i].item() > result.conf[j].item():\n",
    "                        digits_to_discard.append(j)\n",
    "                    else:\n",
    "                        digits_to_discard.append(i)\n",
    "                    \n",
    "        for j in range(len(result.cls)):\n",
    "            if j not in digits_to_discard:\n",
    "                predicted_digits.append(int(result.cls[j].item()))\n",
    "                boxes.append( (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item()))\n",
    "                average_x.append((result.xyxy[j][2].item()+result.xyxy[j][0].item())/2)\n",
    "            \n",
    "        predicted_digits = [x for _,x in sorted(zip(average_x,predicted_digits))]\n",
    "        predicted_boxes = [x for _,x in sorted(zip(average_x,boxes))]\n",
    "        predicted_number =\"\".join([str(i) for i in predicted_digits])\n",
    "        \n",
    "        filename = file.split('.')[0] +'.' + file.split('.')[1] +'.txt'\n",
    "        existing_filepath = os.path.join('datasets','test','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            # Using readlines()\n",
    "            file1 = open(existing_filepath, 'r')\n",
    "            Lines = file1.readlines()\n",
    "            boxes = []\n",
    "            count = 0\n",
    "            number = ''\n",
    "            digits = []\n",
    "            average_x = []\n",
    "            height, width, _ = img.shape\n",
    "            # Strips the newline character\n",
    "            for line in Lines:\n",
    "                count += 1\n",
    "                digits.append(line.split(' ')[0])\n",
    "                average_x.append(line.split(' ')[1])\n",
    "                box = ((float(line.split(' ')[1]) - float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) - float(line.split(' ')[4])/2)*height, (float(line.split(' ')[1]) + float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) + float(line.split(' ')[4])/2)*height)\n",
    "                boxes.append(box)\n",
    "            digits = [x for _, x in sorted(zip(average_x, digits))]\n",
    "            boxes = [x for _, x in sorted(zip(average_x, boxes))]\n",
    "            number =\"\".join([str(i) for i in digits])\n",
    "            correctly_predicted_digits = 0\n",
    "            already_found = []\n",
    "            \"\"\"for i in range(len(predicted_digits)):\n",
    "                for j in range(len(digits)):\n",
    "                    if j not in already_found:\n",
    "                        if calculate_iou(predicted_boxes[i], boxes[j]) >0.5:\n",
    "                            if predicted_digits[i] == int(digits[j]):\n",
    "                                correctly_predicted_digits += 1\n",
    "                                already_found.append(j)\"\"\"\n",
    "\n",
    "            overal_digits+= count\n",
    "            overal_numbers+= 1\n",
    "            overal_predicted_digits += len(predicted_digits)\n",
    "            overal_correct_digits += correctly_predicted_digits\n",
    "            if number == predicted_number:\n",
    "                overal_correct_numbers += 1\n",
    "            field = [filename, number,predicted_number, str(count), correctly_predicted_digits,number == predicted_number, predicted_digits, curr_time]\n",
    "            writer.writerow(field)\n",
    "            progress+=1\n",
    "        if progress % 500 == 0:\n",
    "            print(progress)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571767e0-44f6-46b8-9b1e-dd82b66bb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'the total number of digits in the testing dataset: {overal_digits}')\n",
    "print(f'the number of digits that where predicted: {overal_predicted_digits}')\n",
    "print(f'the digits that were predicted correctly: {overal_correct_digits}')\n",
    "print(f'the amount of numbers that were evaluated: {overal_numbers}')\n",
    "print(f'the numbers that werepredicted correct entirely: {overal_correct_numbers}')\n",
    "print(f'average inference time: {np.sum(np.array(timings))/len(timings)}')\n",
    "\n",
    "\"\"\"\n",
    "with original\n",
    "the total number of digits in the testing dataset: 13920\n",
    "the number of digits that where predicted: 9347\n",
    "the digits that were predicted correctly: 0\n",
    "the amount of numbers that were evaluated: 6000\n",
    "the numbers that werepredicted correct entirely: 2278\n",
    "average inference time: 117.96601511955261\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7fdb3a-eb9b-4d7b-995f-20ccce8cbfda",
   "metadata": {},
   "source": [
    "# do previous tests also on unaugmented images \n",
    "as augmentation may cut of most of the number and still put box around it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474bb28a-77fe-41c9-877c-c8c9811285e4",
   "metadata": {},
   "source": [
    "## first change labels to yolo labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47b5bb06-8c09-4703-9433-9502b6e32af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_yolo(label_path):\n",
    "    with open(label_path) as f:\n",
    "        label = json.load(f)\n",
    "    return label['shapes'], label['imageHeight'], label['imageWidth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7839c726-e85b-4061-adb6-7fdcd7ae62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for partition in ['train','test','val']: \n",
    "    for file in os.listdir(os.path.join('data','back_numbers_deinterlaced',partition,'labels')):\n",
    "        path = os.path.join('data','back_numbers_deinterlaced',partition,'labels', file)\n",
    "        labels, h, w = convert_labels_yolo(path)\n",
    "        yolo = \"\"\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] ==\"background\":\n",
    "                break\n",
    "            yolo = yolo + labels[i]['label']+ ' '\n",
    "            average_x = (labels[i]['points'][1][0]+ labels[i]['points'][0][0])/2\n",
    "            average_y = (labels[i]['points'][1][1]+ labels[i]['points'][0][1])/2\n",
    "            width = labels[i]['points'][1][0]- labels[i]['points'][0][0]\n",
    "            height = labels[i]['points'][1][1]- labels[i]['points'][0][1]\n",
    "            if i!= len(labels)-1:\n",
    "                yolo+= \"{} {} {} {}\\n\".format(average_x/w, average_y/h, width/w, height/h)\n",
    "            else:\n",
    "                yolo+= \"{} {} {} {}\".format(average_x/w, average_y/h, width/w, height/h)\n",
    "        file_path = os.path.join('data','back_numbers_deinterlaced',partition,'labels_new', file.split('.')[0] + '.txt')\n",
    "        with open(file_path, 'w') as file:\n",
    "    \n",
    "            # Write the string to the file\n",
    "            file.write(yolo)\"\"\"\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8970389-3081-4d6d-bb2e-142e0bc71fb4",
   "metadata": {},
   "source": [
    "## no preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1ba288a5-b27d-4852-9d2f-15db6e682542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.345950126647949. Dividing input by 255.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "overal_digits = 0\n",
    "overal_predicted_digits = 0\n",
    "overal_correct_digits = 0\n",
    "overal_numbers = 0\n",
    "overal_correct_numbers = 0\n",
    "with open('test_results_no_preprocess_unaug.csv', 'w', newline='') as csv_file:\n",
    "\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    rep = 0\n",
    "    dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = recognition_model(dummy_input)\n",
    "    timings = []\n",
    "\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    field = [\"filename\", \"backnumber\", \"predicted_number\", \"amount_of_numbers\",\"digits_predicted\", \"number_predicted_correct\", \"number_of_predicted_digits\", \"inference_time\"]\n",
    "    writer.writerow(field)\n",
    "    progress = 0\n",
    "    for file in os.listdir(os.path.join('data','back_numbers_deinterlaced','test', 'images')):\n",
    "\n",
    "        \n",
    "        img = cv2.imread(os.path.join('data','back_numbers_deinterlaced','test','images', file))\n",
    "        starter.record()\n",
    "        results = recognition_model(img, verbose=False)\n",
    "        ender.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings.append(curr_time)\n",
    "        predicted_digits = []\n",
    "        average_x = []\n",
    "        result = results[0].boxes\n",
    "        digits_to_discard = []\n",
    "        boxes = []\n",
    "        for i in range(len(result.cls)):\n",
    "            for j in range(i+1, len(result.cls)):\n",
    "                box1 = (result.xyxy[i][0].item(), result.xyxy[i][1].item(), result.xyxy[i][2].item(), result.xyxy[i][3].item())\n",
    "                box2 = (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item())\n",
    "                iou = calculate_iou(box1, box2)\n",
    "                if iou > 0.5:\n",
    "                    if result.conf[i].item() > result.conf[j].item():\n",
    "                        digits_to_discard.append(j)\n",
    "                    else:\n",
    "                        digits_to_discard.append(i)\n",
    "                    \n",
    "        for j in range(len(result.cls)):\n",
    "            if j not in digits_to_discard:\n",
    "                predicted_digits.append(int(result.cls[j].item()))\n",
    "                boxes.append( (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item()))\n",
    "                average_x.append((result.xyxy[j][2].item()+result.xyxy[j][0].item())/2)\n",
    "            \n",
    "        predicted_digits = [x for _,x in sorted(zip(average_x,predicted_digits))]\n",
    "        predicted_boxes = [x for _,x in sorted(zip(average_x,boxes))]\n",
    "        predicted_number =\"\".join([str(i) for i in predicted_digits])\n",
    "        \n",
    "        filename = file.split('.')[0] +'.txt'\n",
    "        existing_filepath = os.path.join('data','back_numbers_deinterlaced','test','labels_new', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            # Using readlines()\n",
    "            file1 = open(existing_filepath, 'r')\n",
    "            Lines = file1.readlines()\n",
    "            boxes = []\n",
    "            count = 0\n",
    "            number = ''\n",
    "            digits = []\n",
    "            average_x = []\n",
    "            height, width, _ = img.shape\n",
    "            # Strips the newline character\n",
    "            for line in Lines:\n",
    "                count += 1\n",
    "                digits.append(line.split(' ')[0])\n",
    "                average_x.append(line.split(' ')[1])\n",
    "                box = ((float(line.split(' ')[1]) - float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) - float(line.split(' ')[4])/2)*height, (float(line.split(' ')[1]) + float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) + float(line.split(' ')[4])/2)*height)\n",
    "                boxes.append(box)\n",
    "            digits = [x for _, x in sorted(zip(average_x, digits))]\n",
    "            boxes = [x for _, x in sorted(zip(average_x, boxes))]\n",
    "            number =\"\".join([str(i) for i in digits])\n",
    "            correctly_predicted_digits = 0\n",
    "            already_found = []\n",
    "            for i in range(len(predicted_digits)):\n",
    "                for j in range(len(digits)):\n",
    "                    if j not in already_found:\n",
    "                        if calculate_iou(predicted_boxes[i], boxes[j]) >0.5:\n",
    "                            if predicted_digits[i] == int(digits[j]):\n",
    "                                correctly_predicted_digits += 1\n",
    "                                already_found.append(j)\n",
    "\n",
    "            overal_digits+= count\n",
    "            overal_numbers+= 1\n",
    "            overal_predicted_digits += len(predicted_digits)\n",
    "            overal_correct_digits += correctly_predicted_digits\n",
    "            if number == predicted_number:\n",
    "                overal_correct_numbers += 1\n",
    "            field = [filename, number,predicted_number, str(count), correctly_predicted_digits,number == predicted_number, predicted_digits, curr_time]\n",
    "            writer.writerow(field)\n",
    "            progress+=1\n",
    "        if progress % 100 == 0:\n",
    "            print(progress)\n",
    "        \"\"\"if progress >1:\n",
    "            break\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e92c473b-68a6-4ee2-a9eb-a42ea4531321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of digits in the testing dataset: 232\n",
      "the number of digits that where predicted: 227\n",
      "the digits that were predicted correctly: 77\n",
      "the amount of numbers that were evaluated: 95\n",
      "the numbers that werepredicted correct entirely: 64\n",
      "average inference time: 17.871405124664307\n"
     ]
    }
   ],
   "source": [
    "print(f'the total number of digits in the testing dataset: {overal_digits}')\n",
    "print(f'the number of digits that where predicted: {overal_predicted_digits}')\n",
    "print(f'the digits that were predicted correctly: {overal_correct_digits}')\n",
    "print(f'the amount of numbers that were evaluated: {overal_numbers}')\n",
    "print(f'the numbers that werepredicted correct entirely: {overal_correct_numbers}')\n",
    "print(f'average inference time: {np.sum(np.array(timings))/len(timings)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60acd6-7045-4b20-9d5e-af429a612213",
   "metadata": {},
   "source": [
    "## kmeans homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "897b1af0-b3cc-40b5-b1ee-7b9482709243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.718408107757568. Dividing input by 255.\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "overal_digits = 0\n",
    "overal_predicted_digits = 0\n",
    "overal_correct_digits = 0\n",
    "overal_numbers = 0\n",
    "overal_correct_numbers = 0\n",
    "with open('test_results_kmeans_homography_unaug.csv', 'w', newline='') as csv_file:\n",
    "\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    rep = 0\n",
    "    dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = recognition_model(dummy_input)\n",
    "    timings = []\n",
    "\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    field = [\"filename\", \"backnumber\",\"predicted_number\", \"amount_of_numbers\",\"digits_predicted\", \"number_predicted_correct\", \"number_of_predicted_digits\", \"inference_time\"]\n",
    "    writer.writerow(field)\n",
    "    progress = 0\n",
    "    for file in os.listdir(os.path.join('data','back_numbers_deinterlaced','test', 'images')):\n",
    "\n",
    "        \n",
    "        img = cv2.imread(os.path.join('data','back_numbers_deinterlaced','test','images', file))\n",
    "        original = np.copy(img)\n",
    "        img_copy = np.copy(img)\n",
    "        starter.record()\n",
    "        #start_time = time.time()\n",
    "        cnt = get_contours_kmeans_alt(img_copy)\n",
    "        if len(cnt)!= 0:\n",
    "            corners = get_corners_alt(cnt, original)\n",
    "            if len(corners) == 4:\n",
    "                img = unwarp(original, corners)\n",
    "        #print(\"My program took\", time.time() - start_time, \"to run\")\n",
    "        results = recognition_model(img, verbose=False)\n",
    "        ender.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings.append(curr_time)\n",
    "        predicted_digits = []\n",
    "        average_x = []\n",
    "        result = results[0].boxes\n",
    "        digits_to_discard = []\n",
    "        boxes = []\n",
    "        for i in range(len(result.cls)):\n",
    "            for j in range(i+1, len(result.cls)):\n",
    "                box1 = (result.xyxy[i][0].item(), result.xyxy[i][1].item(), result.xyxy[i][2].item(), result.xyxy[i][3].item())\n",
    "                box2 = (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item())\n",
    "                iou = calculate_iou(box1, box2)\n",
    "                if iou > 0.5:\n",
    "                    if result.conf[i].item() > result.conf[j].item():\n",
    "                        digits_to_discard.append(j)\n",
    "                    else:\n",
    "                        digits_to_discard.append(i)\n",
    "                    \n",
    "        for j in range(len(result.cls)):\n",
    "            if j not in digits_to_discard:\n",
    "                predicted_digits.append(int(result.cls[j].item()))\n",
    "                boxes.append( (result.xyxy[j][0].item(), result.xyxy[j][1].item(), result.xyxy[j][2].item(), result.xyxy[j][3].item()))\n",
    "                average_x.append((result.xyxy[j][2].item()+result.xyxy[j][0].item())/2)\n",
    "            \n",
    "        predicted_digits = [x for _,x in sorted(zip(average_x,predicted_digits))]\n",
    "        predicted_boxes = [x for _,x in sorted(zip(average_x,boxes))]\n",
    "        predicted_number =\"\".join([str(i) for i in predicted_digits])\n",
    "        \n",
    "        filename = file.split('.')[0] +'.txt'\n",
    "        existing_filepath = os.path.join('data','back_numbers_deinterlaced','test','labels_new', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            # Using readlines()\n",
    "            file1 = open(existing_filepath, 'r')\n",
    "            Lines = file1.readlines()\n",
    "            boxes = []\n",
    "            count = 0\n",
    "            number = ''\n",
    "            digits = []\n",
    "            average_x = []\n",
    "            height, width, _ = img.shape\n",
    "            # Strips the newline character\n",
    "            for line in Lines:\n",
    "                count += 1\n",
    "                digits.append(line.split(' ')[0])\n",
    "                average_x.append(line.split(' ')[1])\n",
    "                box = ((float(line.split(' ')[1]) - float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) - float(line.split(' ')[4])/2)*height, (float(line.split(' ')[1]) + float(line.split(' ')[3])/2)*width,(float(line.split(' ')[2]) + float(line.split(' ')[4])/2)*height)\n",
    "                boxes.append(box)\n",
    "            digits = [x for _, x in sorted(zip(average_x, digits))]\n",
    "            boxes = [x for _, x in sorted(zip(average_x, boxes))]\n",
    "            number =\"\".join([str(i) for i in digits])\n",
    "            correctly_predicted_digits = 0\n",
    "            already_found = []\n",
    "            \"\"\"for i in range(len(predicted_digits)):\n",
    "                for j in range(len(digits)):\n",
    "                    if j not in already_found:\n",
    "                        if calculate_iou(predicted_boxes[i], boxes[j]) >0.5:\n",
    "                            if predicted_digits[i] == int(digits[j]):\n",
    "                                correctly_predicted_digits += 1\n",
    "                                already_found.append(j)\"\"\"\n",
    "\n",
    "            overal_digits+= count\n",
    "            overal_numbers+= 1\n",
    "            overal_predicted_digits += len(predicted_digits)\n",
    "            overal_correct_digits += correctly_predicted_digits\n",
    "            if number == predicted_number:\n",
    "                overal_correct_numbers += 1\n",
    "            field = [filename, number,predicted_number, str(count), correctly_predicted_digits,number == predicted_number, predicted_digits, curr_time]\n",
    "            writer.writerow(field)\n",
    "            progress+=1\n",
    "        if progress % 10 == 0:\n",
    "            print(progress)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c484d8a1-b521-4686-bbc3-ae2f69dd690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of digits in the testing dataset: 232\n",
      "the number of digits that where predicted: 221\n",
      "the digits that were predicted correctly: 0\n",
      "the amount of numbers that were evaluated: 95\n",
      "the numbers that werepredicted correct entirely: 65\n",
      "average inference time: 324.63011028289793\n"
     ]
    }
   ],
   "source": [
    "print(f'the total number of digits in the testing dataset: {overal_digits}')\n",
    "print(f'the number of digits that where predicted: {overal_predicted_digits}')\n",
    "print(f'the digits that were predicted correctly: {overal_correct_digits}')\n",
    "print(f'the amount of numbers that were evaluated: {overal_numbers}')\n",
    "print(f'the numbers that werepredicted correct entirely: {overal_correct_numbers}')\n",
    "print(f'average inference time: {np.sum(np.array(timings))/len(timings)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a200875-b7e1-4963-918a-2e3c331f932e",
   "metadata": {},
   "source": [
    "## compare results and look why preprocessing doesn't help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9c74045f-6ad2-4ff9-bf25-e603e9321e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "be7e2c87-a4fd-468d-a379-0224c909f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f943cbd7-79b8-11ee-b244-fcb3bc5cd112.25.txt\n",
      "[[11, 0], [51, 0], [50, 35], [2, 46]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'predicted_number'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predicted_number'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[245], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     original \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcircle(original, corners[\u001b[38;5;241m2\u001b[39m], radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     23\u001b[0m     original \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcircle(original, corners[\u001b[38;5;241m3\u001b[39m], radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m number \u001b[38;5;241m=\u001b[39m \u001b[43mfile2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted_number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m number_wrong \u001b[38;5;241m=\u001b[39m file1\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_number\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m real \u001b[38;5;241m=\u001b[39m file1\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbacknumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predicted_number'"
     ]
    }
   ],
   "source": [
    "#file1 = pd.read_csv('test_results_kmeans_homography_unaug.csv')\n",
    "#file2 = pd.read_csv('test_results_no_preprocess_unaug.csv')\n",
    "file1 = pd.read_csv('test_results_kmeans_homography.csv')\n",
    "file2 = pd.read_csv('test_results_no_preprocess.csv')\n",
    "for i in range(file1.shape[0]):\n",
    "    if file1.iloc[i]['number_predicted_correct'] != file2.iloc[i]['number_predicted_correct']:\n",
    "        print(file1.iloc[i]['filename'])\n",
    "        #img = cv2.imread(os.path.join('data','back_numbers_deinterlaced','test','images', (file1.iloc[i]['filename']).split('.')[0] + '.jpg'))\n",
    "        img = cv2.imread(os.path.join('datasets','test','images', (file1.iloc[i]['filename']).split('.')[0]+ '.' + (file1.iloc[i]['filename']).split('.')[1]+ '.jpg'))\n",
    "        img_copy = np.copy(img)\n",
    "        img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
    "        original = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        cnt = get_contours_kmeans_alt(img_copy)\n",
    "        if len(cnt)!= 0:\n",
    "            corners = get_corners_alt(cnt, original)\n",
    "            print(corners)\n",
    "            if len(corners) == 4:\n",
    "                img = unwarp(original, corners)\n",
    "        if len(corners) == 4:\n",
    "            original = cv2.circle(original, corners[0], radius=0, color=(0, 0, 255), thickness=4)\n",
    "            original = cv2.circle(original, corners[1], radius=0, color=(0, 0, 255), thickness=4)\n",
    "            original = cv2.circle(original, corners[2], radius=0, color=(0, 0, 255), thickness=4)\n",
    "            original = cv2.circle(original, corners[3], radius=0, color=(0, 0, 255), thickness=4)\n",
    "        number = file2.iloc[i]['predicted_number']\n",
    "        number_wrong = file1.iloc[i]['predicted_number']\n",
    "        real = file1.iloc[i]['backnumber']\n",
    "        print(f'no preprocess predicted: {number}')\n",
    "        print(f'preprocess predicted: {number_wrong}')\n",
    "        print(f'back number is {real}')\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        plt.imshow(original)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2354ee6b-777b-45c6-9b60-5821a5e17308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_kmeans_alt(img):\n",
    "    original = img.copy()\n",
    "    kimg = img.copy()\n",
    "    kimg = kimg.reshape((img.shape[1]*img.shape[0],3))\n",
    "    img=img.reshape((img.shape[1]*img.shape[0],3))\n",
    "    s=kmeans.fit(img)\n",
    "    labels=kmeans.labels_\n",
    "    centroid=kmeans.cluster_centers_\n",
    "    \n",
    "    good_labels = []\n",
    "    #print(centroid)\n",
    "    \n",
    "    for i in range(len(centroid)):\n",
    "        if centroid[i].max() - centroid[i].min() <35 and centroid[i].min()>135:\n",
    "            good_labels.append(i)\n",
    "    #print(good_labels)\n",
    "    mask = np.zeros(len(labels), dtype = np.uint8)\n",
    "    for i in range(len(labels)):\n",
    "        kimg[i] =[int(centroid[labels[i]][0]), int(centroid[labels[i]][1]), int(centroid[labels[i]][2])]\n",
    "        if labels[i] in good_labels:\n",
    "            mask[i] = 255\n",
    "    kimg = kimg.reshape((original.shape[0],original.shape[1],3))\n",
    "    #print(kimg.shape)\n",
    "    #print(original.shape)\n",
    "    #plt.imshow(kimg)\n",
    "    #plt.show()\n",
    "    mask = mask.reshape((original.shape[0],original.shape[1]))\n",
    "    contours = []\n",
    "    for i in range(mask.shape[0]):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if mask[i,j] == 255:\n",
    "                contours.append([[i,j]])\n",
    "                \n",
    "    #plt.imshow(mask)\n",
    "    #plt.show()\n",
    "    \"\"\"contours, hierarchy = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    if len(contours) != 0:\n",
    "        cnt = sorted(contours, key=cv.contourArea, reverse=True)[0]\n",
    "        print(cnt.shape)\n",
    "        return cnt\"\"\"\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c3a22c0f-386b-4297-b4ae-7294ecb00434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners_alt(cnt,original):\n",
    "    \n",
    "    def find_closest(edge, range_h, range_w):\n",
    "        min_dist = np.inf\n",
    "        closest = [0,0]\n",
    "        for point in cnt:\n",
    "            if range_h[0] <= point[0][0] and point[0][0]<range_h[1] and range_w[0] <= point[0][1] and point[0][1]<range_w[1]:\n",
    "                dist = np.abs(edge[0]-point[0][0])+np.abs(edge[1]-point[0][1])\n",
    "                if dist<min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest = [point[0][1], point[0][0]]\n",
    "        return closest\n",
    "            \n",
    "    def order_corner_points(corners):\n",
    "        # Separate corners into individual points\n",
    "        # Index 0 - top-right\n",
    "        #       1 - top-left\n",
    "        #       2 - bottom-left\n",
    "        #       3 - bottom-right\n",
    "        \n",
    "        top_l, top_r, bottom_r, bottom_l = [None, None], [None, None],[None, None],[None, None]\n",
    "        h,w,_ = original.shape\n",
    "        corners = []\n",
    "        top_l = find_closest([0,0], [0,h//2], [0,w//2])\n",
    "        top_l[1] = top_l[1]-h//10 if top_l[1]-h//10>0 else 0\n",
    "        top_l[0] = top_l[0]-w//10 if top_l[0]-w//10>0 else 0\n",
    "        corners.append(top_l)\n",
    "        #find point closest to [cnt.shape[1]-1,0]\n",
    "        top_r = find_closest([0,w-1],[0,h//2], [w//2, w-1])\n",
    "        top_r[1] = top_r[1]-h//10 if top_r[1]-h//10>0 else 0\n",
    "        top_r[0] = top_r[0]+w//10 if top_r[0]+w//10 < w else w-1\n",
    "        corners.append(top_r)\n",
    "        #find point closest to [cnt.shape[1]-1,cnt.shape[0]-1]\n",
    "        bottom_r= find_closest([h-1,w-1,], [h//2, h-1], [w//2, w-1])\n",
    "        corners.append(bottom_r)\n",
    "        #find point closest to [0,cnt.shape[0]-1]\n",
    "        bottom_l= find_closest([h-1,0], [h//2, h-1], [0,w//2])\n",
    "        corners.append(bottom_l)\n",
    "\n",
    "        \"\"\"top_l[1] = top_l[1]-10 if top_l[1]-10>0 else 0\n",
    "        top_r[1] = top_r[1]-10 if top_r[1]-10>0 else 0\n",
    "        top_l[0] = top_l[0]-10 if top_l[0]-10>0 else 0\n",
    "        top_r[0] = top_r[0]+10 if top_r[0]+10 < original.shape[1] else original.shape[1]-1\n",
    "        return (top_l, top_r, bottom_r, bottom_l)\"\"\"\n",
    "        return corners\n",
    "    \n",
    "    \n",
    "    \n",
    "    corners = order_corner_points(cnt)\n",
    "\n",
    "\n",
    "    \n",
    "    return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0dac0-a5cd-4540-86dd-ae4480e023bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2688ec-fee1-49f0-b780-0ba3ec5553c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
